\section{Introduction}

\citet{roy} uses an approach based on linear mixed effects (LME) models for the purpose of comparing the agreement between two methods of measurement, where replicate measurements on items (often individuals) by both methods are available. She provides three tests of hypothesis appropriate for evaluating the agreement between the two methods of measurement under this sampling scheme. These tests consider null hypotheses that assume: absence of inter-method bias; equality of between-subject variabilities of the two methods; equality of within-subject variabilities of the two methods. By inter-method bias we mean that a systematic difference exists between observations recorded by the two methods. Differences in between-subject variabilities of the two methods arise when one method is yielding average response levels for individuals than are more variable than the average response levels for the same sample of individuals taken by the other method.  Differences in within-subject variabilities of the two methods arise when one method is yielding responses for an individual than are more variable than the responses for this same individual taken by the other method. The two methods of measurement can be considered to agree, and subsequently can be used interchangeably, if all three null hypotheses are true.

\bigskip

Let $y_{mir} $ denote the $r$th replicate measurement on the $i$th item by the $m$th method, where $m=1,2,$ $i=1,\ldots,N,$ and $r = 1,\ldots,n_i.$ When the design is balanced and there is no ambiguity we can set $n_i=n.$ The LME model underpinning Roy's approach can be written
\begin{equation}\label{Roy-model}
y_{mir} = \beta_{0} + \beta_{m} + b_{mi} + \epsilon_{mir}.
\end{equation}
Here $\beta_0$ and $\beta_m$ are fixed-effect terms representing, respectively, a model intercept and an overall effect for method $m.$ The model can be reparameterized by gathering the $\beta$ terms together into (fixed effect) intercept terms $\alpha_m=\beta_0+\beta_m.$ The $b_{1i}$ and $b_{2i}$ terms are correlated random effect parameters having $\mathrm{E}(b_{mi})=0$ with $\mathrm{Var}(b_{mi})=g^2_m$ and $\mathrm{Cov}(b_{1i}, b_{2 i})=g_{12}.$ The random error term for each response is denoted $\epsilon_{mir}$ having $\mathrm{E}(\epsilon_{mir})=0$, $\mathrm{Var}(\epsilon_{mir})=\sigma^2_m$, $\mathrm{Cov}(\epsilon_{1ir}, \epsilon_{2 ir})=\sigma_{12}$, $\mathrm{Cov}(\epsilon_{mir}, \epsilon_{mir^\prime})= 0$ and $\mathrm{Cov}(\epsilon_{1ir}, \epsilon_{2 ir^\prime})= 0.$ Two methods of measurement are in complete agreement if the null hypotheses $\mathrm{H}_1\colon \alpha_1 = \alpha_2$ and $\mathrm{H}_2\colon \sigma^2_1 = \sigma^2_2 $ and $\mathrm{H}_3\colon g^2_1= g^2_2$ hold simultaneously. \citet{roy} uses a Bonferroni correction to control the familywise error rate for tests of $\{\mathrm{H}_1, \mathrm{H}_2, \mathrm{H}_3\}$ and account for difficulties arising due to multiple testing. Roy also integrates $\mathrm{H}_2$ and $\mathrm{H}_3$ into a single testable hypothesis $\mathrm{H}_4\colon \omega^2_1=\omega^2_2,$ where $\omega^2_m = \sigma^2_m + g^2_m$ represent the overall variability of method $m.$  Disagreement in overall variability may be caused by different between-item variabilities, by different within-item variabilities, or by both.  If the exact cause of disagreement between the two methods is not of interest, then the overall variability test $H_4$ is an alternative to testing $H_2$ and $H_3$ separately.

\bigskip

\citet{BXC2008} also use a LME model for the purpose of comparing two methods of measurement where replicate measurements are available on each item. Their interest lies in generalizing the popular limits-of-agreement (LOA) methodology advocated by \citet{BA86} to take proper cognizance of the replicate measurements. \citet{BXC2008} demonstrate statistical flaws with two approaches proposed by \citet{BA99} for the purpose of calculating the variance of the inter-method bias when replicate measurements are available. Instead, \citet{BXC2008} use a fitted mixed effects model to obtain appropriate estimates for the variance of the inter-method bias.  As their interest mainly lies in extending the Bland-Altman methodology, other formal tests are not considered.

\bigskip

\citet{BXC2008} develop their model from a standard two-way analysis of variance model, reformulated for the case of replicate measurements, with random effects terms specified as appropriate. 
Their model describing $y_{mir} $, again the $r$th replicate measurement on the $i$th item by the $m$th method ($m=1,2,$ $i=1,\ldots,N,$ and $r = 1,\ldots,n$), can be written as
\begin{equation}\label{BXC-model}
y_{mir}  = \alpha_{m} + \mu_{i} + a_{ir} + c_{mi} + \epsilon_{mir}.
\end{equation}
The fixed effects $\alpha_{m}$ and $\mu_{i}$  represent the intercept for method $m$ and the `true value' for item $i$ respectively. The random-effect terms comprise an item-by-replicate interaction term $a_{ir} \sim \mathcal{N}(0,\varsigma^{2})$, a method-by-item interaction term $c_{mi} \sim \mathcal{N}(0,\tau^{2}_{m}),$ and model error terms $\varepsilon \sim \mathcal{N}(0,\varphi^{2}_{m}).$ All random-effect terms are assumed to be independent.
For the case when replicate measurements are assumed to be exchangeable for item $i$, $a_{ir}$ can be removed.

%%---Comparative Complexity
There is a substantial difference in the number of fixed parameters used by the respective models. For the model in (\ref{Roy-model}) requires two fixed effect parameters, i.e. the means of the two methods, for any number of items $N$. In contrast, the model described by (\ref{BXC-model}) requires $N+2$ fixed effects for $N$ items. The inclusion of fixed effects to account for the `true value' of each item greatly increases the level of model complexity.

%%---Estimability of Tau
When only two methods are compared, \citet{BXC2008} notes that separate estimates of $\tau^2_m$ can not be obtained due to the model over-specification. To overcome this, the assumption of equality, i.e. $\tau^2_1 = \tau^2_2$, is required.




\newpage
\section{MAY 2012 : Research Notes}
Roy (2009) proposes a suite of hypothesis tests for assessing the agreement of two methods of measurement, when replicate measurements are obtained for each item, using a LME approach. (An item would commonly be a patient).  Two methods of measurement can be said to be in agreement if there is no significant difference between in three key respects. Firstly, there is no inter-method bias between the two methods, i.e. there is no persistent tendency for one method to give higher values than the other.
Secondly, both methods of measurement have the same  within-subject variability. In such a case the variance of the replicate measurements would consistent for both methods.
Lastly, the methods have equal between-subject variability.  Put simply, for the mean measurements for each case, the variances of the mean measurements from both methods are equal.
\subsection{Testing for Inter-method Bias}
Firstly, a practitioner would investigate whether a significant inter-method bias is present between the methods. This bias is specified as a fixed effect in the LME model.  For a practitioner who has a reasonable level of competency in \texttt{R} and undergraduate statistics (in particular simple linear regression model) this is a straight-forward procedure.
\subsection{Reference Model (Ref.Fit)}
Conventionally LME models can be tested using Likelihood Ratio Tests, wherein a reference model is compared to a nested model.
\begin{framed}
\begin{verbatim}
> Ref.Fit = lme(y ~ meth-1, data = dat,   #Symm , Symm#
+     random = list(item=pdSymm(~ meth-1)), 
+     weights=varIdent(form=~1|meth),
+     correlation = corSymm(form=~1 | item/repl), 
+     method="ML")
\end{verbatim}
\end{framed}


Roy(2009) presents two nested models that specify the condition of equality as required, with a third nested model for an additional test. There three formulations share the same structure, and can be specified by making slight alterations of the code for the Reference Model.

\subsection{Nested Model (Between-Item Variability)}
\begin{framed}
\begin{verbatim}
> NMB.fit  = lme(y ~ meth-1, data = dat,   #CS , Symm#
+     random = list(item=pdCompSymm(~ meth-1)),
+     correlation = corSymm(form=~1 | item/repl), 
+     method="ML")
\end{verbatim}
\end{framed}

\newpage

\section{Introduction}

\citet{roy} uses an approach based on linear mixed effects (LME) models for the purpose of comparing the agreement between two methods of measurement, where replicate measurements on items (ofttimes individuals) by both methods are available. She provides three tests of hypothesis appropriate for evaluating the agreement between the two methods of measurement under this sampling scheme. These tests consider null hypotheses that assume: absence of inter-method bias; equality of between-subject variabilities of the two methods; equality of within-subject variabilities of the two methods. By inter-method bias we mean that a systematic difference exists between observations recorded by the two methods. Differences in between-subject variabilities of the two methods arise when one method is yielding average response levels for individuals than are more variable than the average response levels for the same sample of individuals taken by the other method.  Differences in within-subject variabilities of the two methods arise when one method is yielding responses for an individual than are more variable than the responses for this same individual taken by the other method. The two methods of measurement can be considered to agree, and subsequently can be used interchangeably, if all three null hypotheses are true.

\bigskip

%------------------------------------------------------------------------------------------------%
\section{Roy's Hypotheses Tests}

In order to express Roy's LME model in matrix notation we gather all $2n_i$ observations specific to item $i$ into a single vector  $\boldsymbol{y}_{i} = (y_{1i1},y_{2i1},y_{1i2},\ldots,y_{mir},\ldots,y_{1in_{i}},y_{2in_{i}})^\prime.$ The LME model can be written
\[
\boldsymbol{y_{i}} = \boldsymbol{X_{i}\beta} + \boldsymbol{Z_{i}b_{i}} + \boldsymbol{\epsilon_{i}},
\]
where $\boldsymbol{\beta}=(\beta_0,\beta_1,\beta_2)^\prime$ is a vector of fixed effects, and $\boldsymbol{X}_i$ is a corresponding $2n_i\times 3$ design matrix for the fixed effects. The random effects are expressed in the vector $\boldsymbol{b}=(b_1,b_2)^\prime$, with $\boldsymbol{Z}_i$ the corresponding $2n_i\times 2$ design matrix. The vector $\boldsymbol{\epsilon}_i$ is a $2n_i\times 1$ vector of residual terms. Random effects and residuals are assumed to be independent of each other.

The random effects are assumed to be distributed as $\boldsymbol{b}_i \sim \mathcal{N}_2(0,\boldsymbol{G})$. The between-item variance covariance matrix $\boldsymbol{G}$ is constructed as follows:
\[ \boldsymbol{G} =\left(
            \begin{array}{cc}
              g^2_1  & g_{12} \\
              g_{12} & g^2_2 \\
            \end{array}
          \right) \]

% This is probably a good place to discuss how R_i can  be interpreted as a Kroneckor product

The matrix of random errors $\boldsymbol{\epsilon}_i$ is distributed as $\mathcal{N}_2(0,\boldsymbol{R}_i)$.
\citet{hamlett} shows that the variance covariance matrix for the residuals(i.e. the within-item sources of variation between both methods) can be expressed as the Kroneckor product of an $n_i \times n_i$ identity matrix and the partial within-item variance covariance matrix $\boldsymbol{\Sigma}$, i.e. $\boldsymbol{R}_{i} = \boldsymbol{I}_{n_{i}} \otimes \boldsymbol{\Sigma}$.
\[
\boldsymbol{\Sigma} = \left( \begin{array}{cc}
  \sigma^2_{1} & \sigma_{12} \\
  \sigma_{12} & \sigma^2_{2} \\
\end{array}\right),
\]
where $\sigma^2_{1}$ and $\sigma^2_{2}$ are the within-subject variances of the respective methods, and $\sigma_{12}$ is the within-item covariance between the two methods. The within-item variance covariance matrix $\boldsymbol{\Sigma}$ is assumed to be the same for all replications.Computational analysis of linear mixed effects models allow for the explicit analysis of both $\boldsymbol{G}$ and $\boldsymbol{R_i}$.

For expository purposes consider the case where each item provides three replicate measurements by each method. In matrix form the model has the structure
\[
\boldsymbol{y}_{i} =
%---Design Matrix X ----%
\left(\begin{array}{ccc}
 1 & 1 & 0 \\ 1 & 0 & 1 \\ 1 & 1 & 0 \\
 1 & 0 & 1 \\ 1 & 1 & 0 \\ 1 & 0 & 1 \\
\end{array}\right)
%---FE Matrix----%
\left(\begin{array}{c}
 \beta_0 \\ \beta_1 \\ \beta_2 \\
\end{array}\right)
+
%---Design Matrix Z----%
\left(\begin{array}{cc}
1 & 0 \\0 & 1 \\1 & 0 \\0 & 1 \\0 & 1 \\\end{array}
\right)
%---RE Matrix----%
\left(\begin{array}{c}
b_{1i} \\   b_{2i} \\
\end{array}\right)
+
%------Errors Vector---%
\left( \begin{array}{c}
\epsilon_{1i1} \\\epsilon_{2i1} \\\epsilon_{1i2} \\ \epsilon_{2i2} \\\epsilon_{1i3} \\\epsilon_{2i3} \\
\end{array}\right).
\]
The between item variance covariance $\boldsymbol{G}$ is as before, while the within item variance covariance is given as
%------Specification of within item VC matrix R---%
\[
\boldsymbol{R}_i = \left(
\begin{array}{cccccc}
  \sigma^2_{1} & \sigma_{12} & 0 & 0 & 0 & 0 \\
  \sigma_{12} & \sigma^2_{2} & 0 & 0 & 0 & 0 \\
  0 & 0 & \sigma^2_{1} & \sigma_{12} & 0 & 0 \\
  0 & 0 & \sigma_{12} & \sigma^2_{2} & 0 & 0 \\
  0 & 0 & 0 & 0 & \sigma^2_{1} & \sigma_{12} \\
  0 & 0 & 0 & 0 & \sigma_{12} & \sigma^2_{2} \\
\end{array} \right)
\]

The overall variability between the two methods is the sum of between-item variability
$\boldsymbol{G}$ and partial within-item variability $\boldsymbol{\Sigma}$. \citet{roy} denotes the overall variability as ${\mbox{Block - }\boldsymbol \Omega_{i}}$. The overall variation for methods $1$ and $2$ are given by

%------Overall variability in terms of G and R ----%
\begin{equation}
\left(\begin{array}{cc}
              \omega^2_1  & \omega_{12} \\
              \omega_{12} & \omega^2_2 \\
       \end{array}  \right)
 =
\left(\begin{array}{cc}
              g^2_1  & g_{12} \\
              g_{12} & g^2_2 \\
\end{array} \right)
+
\left( \begin{array}{cc}
              \sigma^2_1  & \sigma_{12} \\
              \sigma_{12} & \sigma^2_2 \\
\end{array}\right)
\end{equation}
%------------------------------------------------------------------------%
\newpage
\subsection{Roy's hypothesis tests for variability}
% Three hypothesis tests follow from this equation.
Lack of agreement can arise if there is a disagreement in overall variabilities. This lack of agreement may be due to differing between-item variabilities, differing within-item variabilities, or both. The formulation presented above usefully facilitates a series of significance tests that assess if and where such differences arise. \citet{roy} allows for a formal test of each. These tests are comprised of a formal test for the equality of between-item variances,
\begin{eqnarray*}
\operatorname{H_0} : g^2_1 = g^2_2 \\
\operatorname{H_1} : g^2_1 \neq g^2_2
\end{eqnarray*}
a formal test for the equality of within-item variances,
\begin{eqnarray*}
\operatorname{H_0} : \sigma^2_1 = \sigma^2_2 \\
\operatorname{H_1} : \sigma^2_1 \neq \sigma^2_2
\end{eqnarray*}
and finally, a formal test for the equality of overall variances.
\begin{eqnarray*}
\operatorname{H_0} : \omega^2_1 = \omega^2_2 \\
\operatorname{H_1} : \omega^2_1 \neq \omega^2_2
\end{eqnarray*}

These tests are complemented by the ability to consider the inter-method bias and the overall correlation coefficient.
Two methods can be considered to be in agreement if criteria based upon these methodologies are met. Additionally Roy makes reference to the overall correlation coefficient of the two methods, which is determinable from variance estimates.

\subsection{Computation of limits of agreement under Roy's model}
The limits of agreement \citep{BA86} are ubiquitous in method comparison studies.
The computation thereof require that the variance of the difference of measurements. This variance is easily computable from the  variance estimates in the ${\mbox{Block - }\boldsymbol \Omega_{i}}$ matrix, i.e.
\[
% Check this
\operatorname{Var}(y_1 - y_2) = \sqrt{ \omega^2_1 + \omega^2_2 - 2\omega_{12}}.
\]




%With regards to the specification of the variance terms, Carstensen  remarks that using their approach is common, %remarking that \emph{ The only slightly non-standard (meaning ``not often used") feature is the differing residual %variances between methods }\citep{bxc2010}.

\newpage
\section{Roy's Hypotheses Tests}

In order to express Roy's LME model in matrix notation we gather all $2n_i$ observations specific to item $i$ into a single vector  $\boldsymbol{y}_{i} = (y_{1i1},y_{2i1},y_{1i2},\ldots,y_{mir},\ldots,y_{1in_{i}},y_{2in_{i}})^\prime.$ The LME model can be written
\[
\boldsymbol{y_{i}} = \boldsymbol{X_{i}\beta} + \boldsymbol{Z_{i}b_{i}} + \boldsymbol{\epsilon_{i}},
\]
where $\boldsymbol{\beta}=(\beta_0,\beta_1,\beta_2)^\prime$ is a vector of fixed effects, and $\boldsymbol{X}_i$ is a corresponding $2n_i\times 3$ design matrix for the fixed effects. The random effects are expressed in the vector $\boldsymbol{b}=(b_1,b_2)^\prime$, with $\boldsymbol{Z}_i$ the corresponding $2n_i\times 2$ design matrix. The vector $\boldsymbol{\epsilon}_i$ is a $2n_i\times 1$ vector of residual terms. Random effects and residuals are assumed to be independent of each other.

The random effects are assumed to be distributed as $\boldsymbol{b}_i \sim \mathcal{N}_2(0,\boldsymbol{G})$. The between-item variance covariance matrix $\boldsymbol{G}$ is constructed as follows:
\[ \boldsymbol{G} =\left(
            \begin{array}{cc}
              g^2_1  & g_{12} \\
              g_{12} & g^2_2 \\
            \end{array}
          \right) \]

The matrix of random errors $\boldsymbol{\epsilon}_i$ is distributed as $\mathcal{N}_2(0,\boldsymbol{R}_i)$.
\citet{hamlett} shows that the variance covariance matrix for the residuals(i.e. the within-item sources of variation between both methods) can be expressed as the Kroneckor product of an $n_i \times n_i$ identity matrix and the partial within-item variance covariance matrix $\boldsymbol{\Sigma}$, i.e. $\boldsymbol{R}_{i} = \boldsymbol{I}_{n_{i}} \otimes \boldsymbol{\Sigma}$.
\[
\boldsymbol{\Sigma} = \left( \begin{array}{cc}
  \sigma^2_{1} & \sigma_{12} \\
  \sigma_{12} & \sigma^2_{2} \\
\end{array}\right),
\]
where $\sigma^2_{1}$ and $\sigma^2_{2}$ are the within-subject variances of the respective methods, and $\sigma_{12}$ is the within-item covariance between the two methods. The within-item variance covariance matrix $\boldsymbol{\Sigma}$ is assumed to be the same for all replications.Computational analysis of linear mixed effects models allow for the explicit analysis of both $\boldsymbol{G}$ and $\boldsymbol{R_i}$.

For expository purposes consider the case where each item provides three replicate measurements by each method. In matrix form the model has the structure
\[
\boldsymbol{y}_{i} =
%---Design Matrix X ----%
\left(\begin{array}{ccc}
 1 & 1 & 0 \\ 1 & 0 & 1 \\ 1 & 1 & 0 \\
 1 & 0 & 1 \\ 1 & 1 & 0 \\ 1 & 0 & 1 \\
\end{array}\right)
%---FE Matrix----%
\left(\begin{array}{c}
 \beta_0 \\ \beta_1 \\ \beta_2 \\
\end{array}\right)
+
%---Design Matrix Z----%
\left(\begin{array}{cc}
1 & 0 \\0 & 1 \\1 & 0 \\0 & 1 \\0 & 1 \\\end{array}
\right)
%---RE Matrix----%
\left(\begin{array}{c}
b_{1i} \\   b_{2i} \\
\end{array}\right)
+
%------Errors Vector---%
\left( \begin{array}{c}
\epsilon_{1i1} \\\epsilon_{2i1} \\\epsilon_{1i2} \\ \epsilon_{2i2} \\\epsilon_{1i3} \\\epsilon_{2i3} \\
\end{array}\right).
\]
The between item variance covariance $\boldsymbol{G}$ is as before, while the within item variance covariance is given as
%------Specification of within item VC matrix R---%
\[
\boldsymbol{R}_i = \left(
\begin{array}{cccccc}
  \sigma^2_{1} & \sigma_{12} & 0 & 0 & 0 & 0 \\
  \sigma_{12} & \sigma^2_{2} & 0 & 0 & 0 & 0 \\
  0 & 0 & \sigma^2_{1} & \sigma_{12} & 0 & 0 \\
  0 & 0 & \sigma_{12} & \sigma^2_{2} & 0 & 0 \\
  0 & 0 & 0 & 0 & \sigma^2_{1} & \sigma_{12} \\
  0 & 0 & 0 & 0 & \sigma_{12} & \sigma^2_{2} \\
\end{array} \right)
\]

The overall variability between the two methods is the sum of between-item variability
$\boldsymbol{G}$ and partial within-item variability $\boldsymbol{\Sigma}$. \citet{roy} denotes the overall variability as ${\mbox{Block - }\boldsymbol \Omega_{i}}$. The overall variation for methods $1$ and $2$ are given by

%------Overall variability in terms of G and R ----%
\begin{equation}
\left(\begin{array}{cc}
              \omega^2_1  & \omega_{12} \\
              \omega_{12} & \omega^2_2 \\
       \end{array}  \right)
 =
\left(\begin{array}{cc}
              g^2_1  & g_{12} \\
              g_{12} & g^2_2 \\
\end{array} \right)
+
\left( \begin{array}{cc}
              \sigma^2_1  & \sigma_{12} \\
              \sigma_{12} & \sigma^2_2 \\
\end{array}\right)
\end{equation}
%------------------------------------------------------------------------%
\newpage
\subsection{Roy's hypothesis tests for variability}
% Three hypothesis tests follow from this equation.
Lack of agreement can arise if there is a disagreement in overall variabilities. This lack of agreement may be due to differing between-item variabilities, differing within-item variabilities, or both. The formulation presented above usefully facilitates a series of significance tests that assess if and where such differences arise. \citet{roy} allows for a formal test of each. These tests are comprised of a formal test for the equality of between-item variances,
\begin{eqnarray*}
\operatorname{H_2} : g^2_1 = g^2_2 \\
\operatorname{K_2} : g^2_1 \neq g^2_2
\end{eqnarray*}
and a formal test for the equality of within-item variances.
\begin{eqnarray*}
\operatorname{H_3} : \sigma^2_1 = \sigma^2_2 \\
\operatorname{K_3} : \sigma^2_1 \neq \sigma^2_2
\end{eqnarray*}
A formal test for the equality of overall variances is also presented.
\begin{eqnarray*}
\operatorname{H_4} : \omega^2_1 = \omega^2_2 \\
\operatorname{K_4} : \omega^2_1 \neq \omega^2_2
\end{eqnarray*}

These tests are complemented by the ability to consider the inter-method bias and the overall correlation coefficient.
Two methods can be considered to be in agreement if criteria based upon these methodologies are met. Additionally Roy makes reference to the overall correlation coefficient of the two methods, which is determinable from variance estimates.
