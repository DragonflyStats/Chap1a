%------------------------------------------------------------------------------------------------%
\section{MCS Research Notes}
The problem of comparing two methods of measurement is ubiquitous in scientific literature.
The use of  well-established methodologies, such as the paired t-test, correlation and regression approaches is criticised in Altman and Bland(1983).
In the Bland-Altman papers, the British Standards Institute emerge as the key authority on the definition of the Limits of agreement.
It is assumed that, in the absence of a specified probability, that the level is 95\%.

Bland and Altman proposed a simple graphical technique, plotting the case-wise differences against the case-wise means of the respective measurements.
The benefit of such an approach is the plot makes it easier to assess the magnitude of the disagreement (both error and bias), spot outliers, and see whether there is any trend.

%------------------------------------------------------------------------------------------------%
\subsection{Success of Bland-Altman’s plot}
The success of the Bland-Altman approach is perhaps due to the fact that only a visual inspection of the plot is required. Bland and Altman’s paper was later reported to be the sixth most widely cited statistical paper ever (Hollis 1996, for example).
	Hollis, S (1996), Annals of clinical biochemistry (Annals of Biochemistry 33,1-4)
Ryan, T and Woodall W (2005). The most cited statistical papers Journal of applied Statistics 32(5), 461-474.
Bland and Altman emphasis the clinical importance of the range of between the limits of agreement, and use this range as a basis for evaluating agreement.
The question arises as to whether  or not it is statistically valid to arrive at a decision about the population probability from an observed coverage range in a sample.

Altman and Bland (1983) show that their graphical approach can be supplemented by a test of significance on the Pearson product correlation coefficient of the plotted quantities. This test is equivalent to the test of the hypothesis that the method variances are equal (Pitman 1939)
Bland and Altman recommend a test of significance of Spearman’s rank correlation coefficient of the absolute differences and the case-wise means.
Hayes et al (2006) examines the pitfalls that arises when an outlier is assesses using an informal criterion based on a fixed number of standard deviations rather than a more formal standard approach.
%------------------------------------------------------------------------------------------------%
\subsection{Underlying Model}
The model underlying the Bland-Altman approach can be expressed as an LME model with heterogeneous variances.
y_{ij} = \beta_j + b_i  + \varepsilon_{ij}
The case-wise differences and case-wise means follow a bivariate normal distribution, with expected values and variances specified as [input equations].
%------------------------------------------------------------------------------------------------%
\subsection{Outlier detection}
Additionally, there is no clear guidance in any of the Bland-Altman papers on the treatment of outliers that may arise in a plot.
An example used in Bland-Altman 1986 identifies a “clear outlier”, where it is advised by the authors that “in practice, one could omit this subject”.
Bland and Altman 1999 recommend the computationally intensive approach of calculating the limits of agreement with, and then without, suspected outliers, in order to assess the impact on the results. However, they are clear that they do not recommend excluding outliers from analyses.

%------------------------------------------------------------------------------------------------%
% Good Paper
% http://www.clinchem.org/content/43/11/2039.long
Westgard et al. (1)(2)(3) outlined the basic principles for method comparison in a clear, easy to follow manual. They also introduced the concept of allowable analytical error and gave an overview of published performance criteria. They recommended that the estimated analytical imprecision and bias be compared with these performance criteria in method evaluation as well as in method comparison. Their approach made use of a scatter-plot and calculations based on regression lines, but with confidence limits and judgment of acceptability based on the criteria for allowable analytical error.

These principles of comparing analytical performance with performance criteria, however, have not been universally accepted, and recent publications have criticized the misuse of correlation coefficients (4) and overinterpretation of regression lines in method comparison (5)(6)(7). Bland and Altman (4) recommended the difference plot (or bias plot or residual plot) as an alternative approach for method comparison. On the abscissa they used the mean value of the methods to be compared, to avoid regression towards the mean, and on the ordinate they plotted the calculated difference between measurements by the two methods. They further estimated the mean and standard deviation of differences and displayed horizontal lines for the mean and for ±2 × the standard deviation. However, they missed the concept of a more objective criterion for acceptability. Recently, Hollis (5) has recommended difference plots as the only acceptable method for method comparison studies for publication in Annals of Clinical Biochemistry, but without specifying criteria for acceptability.

However, a few difference plots with evaluation of acceptability according to defined criteria have been published, e.g., in evaluation of estimated biological variation compared with analytical imprecision (8), and in external quality assessment of plasma proteins for the possibilities of sharing common reference intervals (9).

Maybe the scarcity of such publications is more a question of interpretation of the data by plotting than a strict choice between scatter-plot and difference plot, as discussed by Stöckl (10) recently. Investigators seem to rely too much on regression lines and r-values, without doing the equally important interpretation of the data points of the plot. This is becoming more and more disadvantageous with the increasing number of Reference Methods available for comparison with field methods, because in these cases, it is not a question of finding some relationships, but simply of judging the field method to be acceptable or not.

NCCLS has recently published guidelines for method comparison and bias estimation by using patients’ samples (11), where both scatter-plots and bias plots are advised. The document also recommends plotting of single determinations as mean values and stresses the need of visual inspection of data. Further, comparison with performance criteria is recommended, but these criteria are not specified and they are not used in the graphical interpretation. Recently, Houbouyan et al. (12) used ratio plots in their validation protocol of analytical hemostasis systems, where they used a preset, but arbitrarily chosen, acceptance limit of inaccuracy of 15%.

In the following, we will use the difference plot (or bias plot) in combination with simple statistics for the principal judgment of the identity or acceptability of a field method. The difference plot makes it easier to apply the concept; in principle, however, the same evaluations could be performed for a scatter-plot in relation to the line of identity (y = x).

The aim of this contribution is to pay attention to the hypothesis of identity and the concept of acceptable analytical quality in method comparison, especially when one of the methods is a Reference Method.
