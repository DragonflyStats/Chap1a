\documentclass[MASTER.tex]{subfiles}
\begin{document}
	
\chapter{Introduction to Method Comparison Studies}
\section*{Overview}

\begin{itemize}
\item[A:] What is a method comparison study?
\item[B:] A motivating example (Grubb's Fuses)
\item[C:] Agreement and Equivalence
\item[D:] Biases (Constant and Proportional)
\item[E:] Inappropriate assessment of Agreement
\end{itemize}

\newpage
\section{What is a method comparison study?}

% Include Somewhere: An assay is a procedure where a property is measured.

The problem of assessing the agreement between two or more methods
of measurement is ubiquitous in scientific research, and is
commonly referred to as a `method comparison study'. \citet{ludbrook97} states that the purpose of comparing two measurements "of a continuous biological variable" is to uncover systematic differences, not to point to similarities". The need to compare the results of two different measurement techniques is common in medical statistics. Published
examples of method comparison studies can be found in disciplines
as diverse as pharmacology \citep{ludbrook97}, anaesthesia
\citep{Myles}, and cardiac imaging methods \citep{Krumm}.
\smallskip

To illustrate the characteristics of a typical method comparison
study consider the data in Table I \citep{Grubbs73}. In each of
twelve experimental trials, a single round of ammunition was fired
from a 155mm gun and its velocity was measured simultaneously (and
independently) by three chronographs devices, identified here by
the labels `Fotobalk', `Counter' and `Terma'.
\smallskip


\newpage

\begin{table}[ht]
	\begin{center}
		\begin{tabular}{rrrr}
			\hline
			Round& Fotobalk [F] & Counter [C]& Terma [T]\\
			\hline
			1 & 793.8 & 794.6 & 793.2 \\
			2 & 793.1 & 793.9 & 793.3 \\
			3 & 792.4 & 793.2 & 792.6 \\
			4 & 794.0 & 794.0 & 793.8 \\
			5 & 791.4 & 792.2 & 791.6 \\
			6 & 792.4 & 793.1 & 791.6 \\
			7 & 791.7 & 792.4 & 791.6 \\
			8 & 792.3 & 792.8 & 792.4 \\
			9 & 789.6 & 790.2 & 788.5 \\
			10 & 794.4 & 795.0 & 794.7 \\
			11 & 790.9 & 791.6 & 791.3 \\
			12 & 793.5 & 793.8 & 793.5 \\
			\hline
		\end{tabular}
		\caption{Velocity measurement from the three chronographs (Grubbs
			1973).}
	\end{center}
\end{table}

An important aspect of the these data is that all three methods of
measurement are assumed to have an attended measurement error, and
the velocities reported in Table 1.1 can not be assumed to be
`true values' in any absolute sense.

%While lack of
%agreement between two methods is inevitable, the question , as
%posed by \citet{BA83}, is 'do the two methods of measurement agree
%sufficiently closely?'

A method of measurement should ideally be both accurate and precise. \citet{Barnhart} describes agreement as being a broader term that contains both of those qualities. An accurate measurement method will give results close to the unknown `true value'. The precision of a method is indicated by how tightly measurements obtained under identical conditions are distributed around their mean measurement value. A precise and accurate method
will yield results consistently close to the true value. Of course 	a method may be accurate, but not precise, if the average of its measurements is close to the true value, but those measurements
are highly dispersed. Conversely a method that is not accurate may be quite precise, as it consistently indicates the same level of inaccuracy. The tendency of a method of measurement to consistently give results above or below the true value is a source of systematic bias. The smaller the systematic bias, the
greater the accuracy of the method.

% The FDA define precision as the closeness of agreement (degree of
% scatter) between a series of measurements obtained from multiple
% sampling of the same homogeneous sample under prescribed
% conditions. \citet{Barnhart} describes precision as being further
% subdivided as either within-run, intra-batch precision or
% repeatability (which assesses precision during a single analytical
% run), or between-run, inter-batch precision or repeatability
%(which measures precision over time).

In the context of the agreement of two methods, there is also a tendency of one measurement method to consistently give results above or below the other method. Lack of agreement is a consequence of the existence of `inter-method bias'. For two methods to be considered in good agreement, the inter-method bias should be in the region of zero. A simple estimation of the inter-method bias can be calculated using the differences of the
paired measurements. The data in Table 1.2 are a good example of
possible inter-method bias; the `Fotobalk' consistently recording
smaller velocities than the `Counter' method. Consequently one
would conclude that there is lack of agreement between the two
methods.

The absence of inter-method bias by itself is not sufficient to
establish whether two measurement methods agree. The two methods
must also have equivalent levels of precision. Should one method
yield results considerably more variable than those of the other,
they can not be considered to be in agreement. With this in mind a
methodology is required that allows an analyst to estimate the
inter-method bias, and to compare the precision of both methods of
measurement.
\newpage
% latex table generated in R 2.6.0 by xtable 1.5-5 package
% Wed Aug 26 15:22:41 2009
\begin{table}[h!]
	
	\begin{center}
		
		\begin{tabular}{rrrr}
			\hline
			Round& Fotobalk (F) & Counter (C) & F-C \\
			\hline
			1 & 793.8& 794.6 & -0.8 \\
			2 & 793.1 & 793.9 & -0.8 \\
			3 & 792.4 & 793.2 & -0.8 \\
			4 & 794.0 & 794.0 & 0.0 \\
			5 & 791.4 & 792.2 & -0.8 \\
			6 & 792.4 & 793.1 & -0.7 \\
			7 & 791.7 & 792.4 & -0.7 \\
			8 & 792.3 & 792.8 & -0.5 \\
			9 & 789.6 & 790.2 & -0.6 \\
			10 & 794.4 & 795.0 & -0.6 \\
			11 & 790.9 & 791.6 & -0.7 \\
			12 & 793.5 & 793.8 & -0.3 \\
			\hline
		\end{tabular}
		\caption{Difference between Fotobalk and Counter measurements.}
	\end{center}
\end{table}

%----------------------------------------------------------------------------%
\subsection{Inappropriate assessment of Agreement}
\subsubsection{Paired T tests} This method can be applied to test for
statistically significant deviations in bias. This method can be
potentially misused for method comparison studies.
\\It is a poor measure of agreement when the rater's measurements
are perpendicular to the line of equality[Hutson et al]. In this
context, an average difference of zero between the two raters, yet
the scatter plot displays strong negative correlation.
\subsubsection{Inappropriate Methodologies} Use of the Pearson
Correlation Coefficient , although seemingly intuitive, is not
appropriate approach to assessing agreement of two methods.
Arguments against its usage have been made repeatedly in the
relevant literature. It is possible for two analytical methods to
be highly correlated, yet have a poor level of agreement.
\subsubsection{Pearson's Correlation Coefficient} It is well known that
Pearson's correlation coefficient is a measure of the linear
association between two variables, not the agreement between two
variables (e.g., see Bland and Altman 1986)..This is a well known
as a measure of linear association between two
variables.Nonetheless this is not necessarily the same as
Agreement. This method is considered wholly inadequate to assess
agreement because it only evaluates only the association of two
sets of observations.

%----------------------------------------------------------------------------%
\subsection{Inappropriate use of the Correlation Coefficient}
It is intuitive when dealing with two sets of related data, i.e
the results of the two raters,  to calculate the correlation
coefficient (r). Bland and Altman attend to this in their $1999$
paper.

They present a data set from two sets of meters, and an
accompanying scatterplot. An hypothesis test on the data set leads
us to conclude that there is a relationship between both sets of
meter measurements. The correlation coeffiecient is determined to
be r =0.94.However, this high correlation does not mean that the
two methods agree. It is possible to determine from the
scatterplot that the intercept is not zero, a requirement for
stating both methods have high agreement. Essentially, should two
methods have highly correlated results, it does not follow that
they have high agreement.

\subfile{Repeatability.tex}
\newpage

\section{Agreement}
Bland and Altman (1986) defined perfect agreement as the case where all of the pairs of rater data lie along the line of equality, where the line of equality is defined as the 45 degree line passing through the origin. To carry their idea a step further, we define a specific numerical measure of agreement as twice the expected squared perpendicular distance of the pair of random variables ($X1$, $X2$) to the line of equality or agreement in the $(X1,X2)$-plane, that is, $E(X1 - X2)2$, where X1 and X2 denote the continuous measurements of rater 1 and rater 2, respectively.\\

Obviously, other $L_p$ norms may be considered for the purpose of numerically measuring agreement and warrant future consideration. Note that we will use the term rater and measuring device interchangeably throughout this article.

\citet{BA86} define perfect agreement as 'The case where all of the pairs of rater data lie
along the line of equality'. The Line of Equality is defined as the 45 degree line passing through the origin, or X=Y on a XY plane.

Agreement is the extent to which the measure of the variable of interest, under a constant set of experimental conditions, yields the same result on repeated trials (Sanchez et al). The more consistent the results, the more reliable the measuring procedure.

In particular, in medicine, new methods or devices that are cheaper, easier to use, or less invasive, are routinely developed. Agreement between a new method and either a traditional reference or gold standard must be evaluated before the new one is put into practice. Various methodologies have been proposed for this purpose in recent years.

\section{Constant and Proportional Bias}
\begin{itemize}
\item[Constant Bias] This is a form of systematic deviations estimated as the average difference between the test
and the reference method.
\item[Proportional Bias] Two methods may agree on average, but they may exhibit differences over a range of measurements.
\end{itemize}

Proportional Bias is a difference in the two measures which is proportional to the scale of the measurement. \\Using a naive estimation of bias, such as the mean of differences, it may incorrectly indicate absence of bias, by yielding a mean difference close to zero. This would be caused by positive differences in the measurements at one end of the range of measurements being canceled out by negative differences at the other end of the scale.

\section{Normality of Case-wise Differences}

The difference are assumed to be normally distributed, although the measurements themselves are not assumed to follow any distribution.Therefore the authors argue that the 95\% of differences are expected to lie within these limits. This assumption is justified because variation between subjects has been removed, leaving only measurement error \citep{BA86}. There are formal methodologies to test whether this assumption holds.


The problem of assessing the agreement between two or more methods
of measurement is ubiquitous in scientific research, and is
commonly referred to as a `method comparison study'. Published
examples of method comparison studies can be found in disciplines
as diverse as Pharmacology \citep{ludbrook97}, Anaesthesia
\citep{Myles}, and cardiac imaging methods \citep{Krumm}.
\smallskip

To illustrate the characteristics of a typical method comparison
study consider the data in Table I, taken from \citet{Grubbs73}.
In each of twelve experimental trials a single round of ammunition
was fired from a 155mm gun, and its velocity was measured
simultaneously (and independently) by three chronographs devices,
referred to here as `Fotobalk', `Counter' and `Terma'.
\smallskip


\newpage

\begin{table}[ht]
\begin{center}
\begin{tabular}{rrrr}
  \hline
  Round& Fotobalk [F] & Counter [C]& Terma [T]\\
  \hline
  1 & 793.8 & 794.6 & 793.2 \\
  2 & 793.1 & 793.9 & 793.3 \\
  3 & 792.4 & 793.2 & 792.6 \\
  4 & 794.0 & 794.0 & 793.8 \\
  5 & 791.4 & 792.2 & 791.6 \\
  6 & 792.4 & 793.1 & 791.6 \\
  7 & 791.7 & 792.4 & 791.6 \\
  8 & 792.3 & 792.8 & 792.4 \\
  9 & 789.6 & 790.2 & 788.5 \\
  10 & 794.4 & 795.0 & 794.7 \\
  11 & 790.9 & 791.6 & 791.3 \\
  12 & 793.5 & 793.8 & 793.5 \\
   \hline
\end{tabular}
\caption{Measurement of the three chronographs (Grubbs 1973)}
\end{center}
\end{table}

An important aspect of the these data is that all three methods of
measurement are assumed to have an attended measurement error, and
the velocities reported in Table I can not be assumed to be `true
values' in any absolute sense. For expository purposes only the
first two methods `Fotobalk' and `Counter' will enter in the
immediate discussion.

%While lack of
%agreement between two methods is inevitable, the question , as
%posed by \citet{BA83}, is 'do the two methods of measurement agree
%sufficiently closely?'

A method of measurement should ideally be both accurate and precise.An accurate measurement methods shall give a result close to the `true value'. Precision of a method is indicated by how tightly clustered its measurements are around their mean measurement value.

A precise and accurate method should yield results consistently close to the true value. However a method may be accurate, but not precise. The average of its measurements is close to the true
value, but those measurements are highly dispersed. Conversely an inaccurate method may be quite precise , as it consistently indicates the same level of inaccuracy.

The tendency of a method of measurement to consistently give results above or below the true value is a source of systematic bias. The lesser the systematic bias, the greater the accuracy of the method.

In the context of the agreement of two methods, there is also a tendency of one measurement method to consistently give results above or below the other method. Lack of agreement is a consequence of the existence of `inter-method bias'. For two methods to be considered in good agreement, the inter-method bias should be in the region of zero.

A simple estimation of the inter-method bias can be calculated using the differences of the paired measurements. The data in Table 1.2 are a good example of possible inter-method bias; the `Fotobalk' consistently recording smaller velocities than the `Counter' method. Consequently there is lack of agreement between the two methods.
\newpage
% latex table generated in R 2.6.0 by xtable 1.5-5 package
% Wed Aug 26 15:22:41 2009
\begin{table}[h!]
\begin{center}

\begin{tabular}{rrrr}
  \hline
 Round& Fotobalk (F) & Counter (C) & F-C \\
  \hline
1 & 793.80 & 794.60 & -0.80 \\
  2 & 793.10 & 793.90 & -0.80 \\
  3 & 792.40 & 793.20 & -0.80 \\
  4 & 794.00 & 794.00 & 0.00 \\
  5 & 791.40 & 792.20 & -0.80 \\
  6 & 792.40 & 793.10 & -0.70 \\
  7 & 791.70 & 792.40 & -0.70 \\
  8 & 792.30 & 792.80 & -0.50 \\
  9 & 789.60 & 790.20 & -0.60 \\
  10 & 794.40 & 795.00 & -0.60 \\
  11 & 790.90 & 791.60 & -0.70 \\
  12 & 793.50 & 793.80 & -0.30 \\
   \hline
\end{tabular}
\caption{Difference between Fotobalk and Counter measurements}
\end{center}
\end{table}

\bigskip

\noindent The absence of inter-method bias by itself is not sufficient to establish whether two measurement methods agree or not. These methods must also have equivalent levels of precision. Should one method yield results considerably more variable than that of the other, they can not be considered to be in agreement.

Therefore a methodology must be introduced that allows an analyst to estimate the inter-method bias, and to compare the precision of both methods of measurement.


%Also the variances of the results from both methods should not be
%significantly different. There are well established methods for
%determining whether variance of two data sets are equal ,such as
%the Pitman-Morgan test \citep{Pitman} \citep{Morgan}.

%Precision  may be defined as as the quality that results of two
%methods shall have similar variance , consistently throughout the
%range of measurement.

\section{Inappropriate assessment of Agreement}
\subsection{Paired T tests} This method can be applied to test for
statistically significant deviations in bias. This method can be
potentially misused for method comparison studies.
\\It is a poor measure of agreement when the rater's measurements
are perpendicular to the line of equality[Hutson et al]. In this
context, an average difference of zero between the two raters, yet
the scatter plot displays strong negative correlation.
\subsection{Inappropriate Methodologies} Use of the Pearson
Correlation Coefficient , although seemingly intuitive, is not
appropriate approach to assessing agreement of two methods.
Arguments against its usage have been made repeatedly in the
relevant literature. It is possible for two analytical methods to
be highly correlated, yet have a poor level of agreement.
\subsection{Pearson's Correlation Coefficient} It is well known that
Pearson's correlation coefficient is a measure of the linear
 association between two variables, not the agreement between two
 variables (e.g., see Bland and Altman 1986)..This is a well known
as a measure of linear association between two
variables.Nonetheless this is not necessarily the same as
Agreement. This method is considered wholly inadequate to assess
agreement because it only evaluates only the association of two
sets of observations.

\newpage
\subsection{Lack Of Agreement}


\subsubsection*{Constant Bias} This is a form of systematic
deviations estimated as the average difference between the test
and the reference method


\subsubsection*{Proportional Bias} Two methods may agree on
average, but they may exhibit differences over a range of
measurements.



\subfile{ConversionGoldStandard.tex}
%======================================================================================= %
\newpage


\bibliography{DB-txfrbib}
\end{document}